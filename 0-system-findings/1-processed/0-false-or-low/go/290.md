
- [290.md](processed/false/go/290.md): #false
  - **Description:** Misunderstanding of sync.Pool
  - **Reason:** The reporter misunderstands how sync.Pool works. sync.Pool will return a new buffer object for each invocation of Get(). Get() is thread safe, so it's fine to call it across multiple goroutines. It doesn't matter if the buffer is undersized for large payloads, because it gets resized if the payload is larger than the default buffer. There is no single buffer to fill, because sync.Pool will create new buffers as necessary.
  - **Action:** No action

---

obront

medium

# PayloadBufPool Allocation Overflow

## Summary
A malicious sequencer can gossip a large number of specially crafted blocks to the L2 consensus layer and fill other op-node clients' `payloadBufPool`, causing a denial of service for these peers.

## Vulnerability Detail
`op-node/eth/ssz.go` uses a `sync.Pool()` to optimize memory allocations for processing `ExecutionPayload` `ssz` objects that it sends and recieves over gossip. This pool is initialized with a 100K byte buffer which is shared for both marshaling and unmarshaling ExecutionPayload objects leaving it vulnerable to overflow.

There are multiple aspects of this setup that an attacker can compound to abuse it:

- The `ExecutionPayload` object's size is dynamic and can be very large. A single payload can be larger than the 100K byte buffer: `508 bytes + ExtraData + (1048576 max transactions) * len(tx)`
- The processing of these incoming payloads from gossip is async, leading to an arbitrary number of go routines using the `PayloadBufPool` at the same time.
- The same `PayloadBufPool` is used by marshaling and unmarshalling routines at the same time

A malicious sequencer can spam the network with a large number of specially crafted blocks (large, containing lots of transactions), filling the `payloadBufPool`'s of all other op-nodes (who would gossip these blocks to all other nodes, likely even those not peered with the sequencer). This will fill their buffers and cause a DOS of the network.

In older `sync.Pool` implementations this will cause a `slice index out-of-bounds` panic. In newer `sync.Pool` implementations `Get()` will act as `New()` when the pool's buffer is full, leading to large allocations that are never collected by the GC (a characteristic of `sync.Pool` objects). This can manifest similar characteristics of a memory leak and lead to out-of-memory DOS in clients.

## Impact
A single malicious sequencer can DOS a large portion of the L2 consensus layer.

## Code Snippet
[[link](https://github.com/ethereum-optimism/optimism/blob/3f4b3c328153a8aa03611158b6984d624b17c1d9/op-node/p2p/gossip.go#L384)] `JoinGossip()` registers the `guardGossipValidator()` handler, which calls `payload.UnmarshalSSZ()` (utilizes the `PayloadBufPool`) on each new block recieved.
```go
func JoinGossip(p2pCtx context.Context, self peer.ID, ps *pubsub.PubSub, log log.Logger, cfg *rollup.Config, runCfg GossipRuntimeConfig, gossipIn GossipIn) (GossipOut, error) {
   val := guardGossipValidator(log, logValidationResult(self, "validated block", log, BuildBlocksValidator(log, cfg, runCfg)))
   blocksTopicName := blocksTopicV1(cfg)
   err := ps.RegisterTopicValidator(blocksTopicName,
       val,
       pubsub.WithValidatorTimeout(3*time.Second),
       pubsub.WithValidatorConcurrency(4))
```
[[link](https://github.com/ethereum-optimism/optimism/blob/3f4b3c328153a8aa03611158b6984d624b17c1d9/op-node/rollup/driver/state.go#L172)] `completeNewBlock()` calls `s.network.PublishL2Payload()` which calls `payload.MarshalSSZ()` (utilizes the `PayloadBufPool`) on each publishing of an L2 block to the network.
```go
// completeNewBlock completes a previously started L2 block sequencing job.
func (s *Driver) completeNewBlock(ctx context.Context) error {
   payload, err := s.sequencer.CompleteBuildingBlock(ctx)
   if err != nil {
       s.metrics.RecordSequencingError()
       s.log.Error("Failed to seal block as sequencer", "err", err)
       return err
   }


   // Generate an L2 block ref from the payload.
   newUnsafeL2Head, err := derive.PayloadToBlockRef(payload, &s.config.Genesis)
   if err != nil {
       s.metrics.RecordSequencingError()
       s.log.Error("Sequenced payload cannot be transformed into valid L2 block reference", "err", err)
       return fmt.Errorf("sequenced payload cannot be transformed into valid L2 block reference: %w", err)
   }


   // Update our L2 head block based on the new unsafe block we just generated.
   s.derivation.SetUnsafeHead(newUnsafeL2Head)


   s.log.Info("Sequenced new l2 block", "l2_unsafe", newUnsafeL2Head, "l1_origin", newUnsafeL2Head.L1Origin, "txs", len(payload.Transactions), "time", newUnsafeL2Head.Time)
   s.metrics.CountSequencedTxs(len(payload.Transactions))


   if s.network != nil {
       if err := s.network.PublishL2Payload(ctx, payload); err != nil {
           s.log.Warn("failed to publish newly created block", "id", payload.ID(), "err", err)
           s.metrics.RecordPublishingError()
           // publishing of unsafe data via p2p is optional. Errors are not severe enough to change/halt sequencing but should be logged and metered.
       }
   }
   return nil
}
```
[[link](https://github.com/ethereum-optimism/optimism/blob/3f4b3c328153a8aa03611158b6984d624b17c1d9/op-node/eth/ssz.go#L64)]  `ExecutionPayload.MarshalSSZ()`:
```go
// MarshalSSZ encodes the ExecutionPayload as SSZ type
func (payload *ExecutionPayload) MarshalSSZ(w io.Writer) (n int, err error) {
   if len(payload.ExtraData) > math.MaxUint32-executionPayloadFixedPart {
       return 0, ErrExtraDataTooLarge
   }


   scope := payload.SizeSSZ()


   buf := *payloadBufPool.Get().(*[]byte)
   if uint32(cap(buf)) < scope {
       buf = make([]byte, scope)
   } else {
       buf = buf[:scope]
   }
   defer payloadBufPool.Put(&buf)
   #...
   # <processing>
   #...
```
[[link](https://github.com/ethereum-optimism/optimism/blob/3f4b3c328153a8aa03611158b6984d624b17c1d9/op-node/eth/ssz.go#L134)] `ExecutionPayload.UnmarshalSSZ()`:
```go
// UnmarshalSSZ decodes the ExecutionPayload as SSZ type
func (payload *ExecutionPayload) UnmarshalSSZ(scope uint32, r io.Reader) error {
   if scope < executionPayloadFixedPart {
       return fmt.Errorf("scope too small to decode execution payload: %d", scope)
   }


   buf := *payloadBufPool.Get().(*[]byte)
   if uint32(cap(buf)) < scope {
       buf = make([]byte, scope)
   } else {
       buf = buf[:scope]
   }
   defer payloadBufPool.Put(&buf)
   #...
   # <processing>
   #...
```
[[link](https://github.com/ethereum-optimism/optimism/blob/3f4b3c328153a8aa03611158b6984d624b17c1d9/op-node/eth/ssz.go#L35)] Dynamic sizing of `ExecutionPayload` `ssz` objects can be abused to create very large objects to fill the buffer:
```go
func (payload *ExecutionPayload) SizeSSZ() (full uint32) {
   full = executionPayloadFixedPart + uint32(len(payload.ExtraData))
   // One offset to each transaction
   full += uint32(len(payload.Transactions)) * 4
   // Each transaction
   for _, tx := range payload.Transactions {
       full += uint32(len(tx))
   }
   return full
}
```
[[link](https://github.com/ethereum-optimism/optimism/blob/3f4b3c328153a8aa03611158b6984d624b17c1d9/op-node/eth/ssz.go#L17)] executionPayloadFixedPart size:


```go
const executionPayloadFixedPart = 32 + 20 + 32 + 32 + 256 + 32 + 8 + 8 + 8 + 8 + 4 + 32 + 32 + 4
```
calculation:
```python
Python 3.8.10 (default, Nov 14 2022, 12:59:47)
[GCC 9.4.0] on linux
>>> # executionPayloadFixedPart size
>>> 32 + 20 + 32 + 32 + 256 + 32 + 8 + 8 + 8 + 8 + 4 + 32 + 32 + 4
508
```
[[link](https://github.com/ethereum-optimism/optimism/blob/3f4b3c328153a8aa03611158b6984d624b17c1d9/op-node/eth/ssz.go#L19)] max transactions per payload:
```go
// MAX_TRANSACTIONS_PER_PAYLOAD in consensus spec
const maxTransactionsPerPayload = 1 << 20
```
calculation:
```python
Python 3.8.10 (default, Nov 14 2022, 12:59:47)
[GCC 9.4.0] on linux
>>> # MAX_TRANSACTIONS_PER_PAYLOAD
>>> 1 << 20
1048576
```
[[link](https://github.com/ethereum-optimism/optimism/blob/3f4b3c328153a8aa03611158b6984d624b17c1d9/op-node/eth/ssz.go#L28)] Sync.Pool initialization:
```go
var payloadBufPool = sync.Pool{New: func() any {
   x := make([]byte, 0, 100_000)
   return &x
}}
```
## Tool used

Manual Review

## Recommendation
- Increase the `payloadBufPool` to be greater than the max size of the object
- Use different buffers for marshaling and unmarshalling
- Protect the `payloadBufPool` with a mutex so that Get() and Put() are guaranteed to be run sequentially before another thread can grab buffer pool memory
- Throttle the number of `ExecutionPayload` objects that can be processed in a given period of time